{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #11"
      ],
      "metadata": {
        "id": "mlHt3eBtDcuI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMoXdgLYHmVc"
      },
      "outputs": [],
      "source": [
        "!pip install pythainlp\n",
        "!wget http://www.donlapark.cmustat.com/229352/thai_lyrics.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4htrTvCOhPBD"
      },
      "source": [
        "# Song lyrics generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ51vFVH8uhg"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import csv\n",
        "from itertools import chain\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from pythainlp import word_tokenize\n",
        "\n",
        "\n",
        "df = pd.read_csv('thai_lyrics.csv', engine='python')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF8se3vr9IE6"
      },
      "outputs": [],
      "source": [
        "tokenized_lyrics = df['lyrics'].map(word_tokenize)\n",
        "print(tokenized_lyrics[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEg_FFZcg2hn"
      },
      "source": [
        "### Convert from words to numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laZhsugj40XF"
      },
      "outputs": [],
      "source": [
        "#[[song , number , one],[song , number , two]] -> [song , number , one , song , number , two]\n",
        "def flatten(ls):\n",
        "    \"\"\"\n",
        "    Flatten list of list\n",
        "    \"\"\"\n",
        "    return list(chain.from_iterable(ls))\n",
        "\n",
        "#[song , number ,one, number, two] -> [1,2,3,2,4] and [1,2,3] -> [song , number , one]\n",
        "def create_lookup_dict(tokenized_lyrics, n_min=None):\n",
        "    \"\"\"\n",
        "    Create lookup dictionary from list of words (lyrics)\n",
        "    \"\"\"\n",
        "    word_counts = Counter(tokenized_lyrics)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    if n_min is not None:\n",
        "        sorted_vocab = {k: v for k, v in word_counts.items() if v >= n_min}\n",
        "    vocab_to_int = {word: i for i, word in enumerate(sorted_vocab, 0)}\n",
        "    int_to_vocab = {i: word for word, i in vocab_to_int.items()}\n",
        "    return (vocab_to_int, int_to_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7h76Ddh5pxy"
      },
      "outputs": [],
      "source": [
        "tokenized_lyrics = flatten(tokenized_lyrics)\n",
        "tokenized_lyrics = [token if token != '\\n' else ' ' for token in tokenized_lyrics]\n",
        "word_counts = Counter(tokenized_lyrics)\n",
        "vocab_to_int, int_to_vocab = create_lookup_dict(tokenized_lyrics, n_min=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i49_sKArgkeQ"
      },
      "outputs": [],
      "source": [
        "vocab_to_int[\"ใคร\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji5YtYv2vqq4"
      },
      "outputs": [],
      "source": [
        "len(vocab_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDeFF62ngkmN"
      },
      "outputs": [],
      "source": [
        "int_to_vocab[12]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgUDR6WZgqCi"
      },
      "source": [
        "### Create Features (4 words in a song) and Target (the next word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaH7s1JS6rXB"
      },
      "outputs": [],
      "source": [
        "sequence_length = 4\n",
        "\n",
        "tokenized_indices = [vocab_to_int.get(token, 0) for token in tokenized_lyrics]\n",
        "\n",
        "X, target = [], []\n",
        "for n in range(0, len(tokenized_indices) - sequence_length, 1):\n",
        "  x = tokenized_indices[n: n + sequence_length]\n",
        "  y = tokenized_indices[n + sequence_length]\n",
        "  X.append(np.array(x))\n",
        "  target.append(y)\n",
        "X = np.array(X)\n",
        "target = np.array(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP_j2yBfgjEP"
      },
      "outputs": [],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Re-6oe-gjdB"
      },
      "outputs": [],
      "source": [
        "target[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M42FcfW2LgiH"
      },
      "outputs": [],
      "source": [
        "class MyDataSet(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super(MyDataSet, self).__init__()\n",
        "    self._X = X\n",
        "    self._y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self._X[index]\n",
        "    y = self._y[index]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9FTHz2eLqpW"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Classification\n",
        "NUM_CLASSES = 25203\n",
        "\n",
        "dataset = MyDataSet(X, target)\n",
        "\n",
        "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxaVQAwqUTwl"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4L6bwtBUZnw"
      },
      "source": [
        "1. `nn.Embedding(num_embeddings, embedding_dim)` [Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "\n",
        "![emb](https://miro.medium.com/max/720/1*NuWIU2Iew3Bm8NR78tRj8A.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPuELnL_UnsX"
      },
      "source": [
        "2. LSTM [Documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMDmCYN6Svkb"
      },
      "source": [
        "![lstm](https://i.stack.imgur.com/sBEBp.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZivdouMU0F2"
      },
      "outputs": [],
      "source": [
        "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
        "input = torch.randn(5, 3, 10)  # (batch_size, time_steps, input_size)\n",
        "h0 = torch.randn(2, 5, 20)  # (num_layers, batch_size, hidden_size)\n",
        "c0 = torch.randn(2, 5, 20)  # (num_layers, batch_size, hidden_size)\n",
        "output, (h1, c1) = lstm(input, (h0, c0))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwDMjEUPdn6Z"
      },
      "source": [
        "### Exercise 1: Fill in the code in `TODO 1` and `TODO 2` with the following requirements:\n",
        "\n",
        "- The embedding layer must transform the one-hot-encoding input into a vector of 200 dimension\n",
        "- The model must have a stack of 2 LSTMs\n",
        "- Each LSTM's hidden state vectors must have 256 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOXkBy9ENokC"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Self\n",
        "class Simple_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple_LSTM, self).__init__()\n",
        "\n",
        "        # TODO 1: Fill in the layers' parameters\n",
        "        # The output of the final layer must be a vector representing the next word\n",
        "        self.embeddings = nn.Embedding(num_embeddings= , embedding_dim= )\n",
        "        self.lstm = nn.LSTM(input_size= , hidden_size= , num_layers= , dropout=0.2, batch_first=True)\n",
        "        self.fc = nn.Linear( , )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO 2: Apply the Embedding layer\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpZ_4U85IqcB"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Simple_LSTM().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPALHPWyeH_V"
      },
      "source": [
        "### Exercise 2: fill in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLRparXRIrZ9"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 1000 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def generate(model, start_word, pad_value=0, predict_len=40):\n",
        "    # Tokenize the input sentence\n",
        "    words = word_tokenize(start_word)\n",
        "    start_word_ids = []\n",
        "    # List to store the predictions\n",
        "    predicted = words\n",
        "\n",
        "    # Words -> Integers\n",
        "    word_ids = [vocab_to_int.get(word, pad_value) for word in words]\n",
        "\n",
        "    #[28,15,16] -> [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,15,16]\n",
        "    current_seq = [np.pad(word_ids, (4 - len(word_ids), pad_value), 'constant')]\n",
        "\n",
        "    for _ in range(predict_len):\n",
        "        current_seq = torch.LongTensor(np.array(current_seq)).to(device)\n",
        "        # get the next word probabilities\n",
        "        p = model(current_seq)\n",
        "        p = nn.Softmax(dim=1)(p).to(device).detach().numpy()\n",
        "        # p = [[0.1,0.2,0.05,0.03,0.02,0.3,0.2,0.1]]\n",
        "        p = p[0]\n",
        "        # p = [0.1,0.2,0.05,0.03,0.02,0.3,0.2,0.1]\n",
        "\n",
        "\n",
        "        # Sample from probability distribution p\n",
        "        word_i = np.random.choice(np.arange(0, p.shape[0]), p=p)\n",
        "        #word_i is an integer representing a word.\n",
        "\n",
        "        #### TODO: Fill in the following two lines of code#########\n",
        "        # 1. Convert from word_i (int)--> word (str)\n",
        "\n",
        "        # 2. Append the word from 1. into `predicted` list.\n",
        "\n",
        "        ##################end#####################################\n",
        "\n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = current_seq.detach().to(device).detach().numpy()\n",
        "        current_seq = np.roll(current_seq, -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    gen_sentences = ''.join(predicted)\n",
        "    return gen_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-9hflaPec0j"
      },
      "source": [
        "### Exercise 3: use `generate` function to generate new text for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GInZpHdqI8p2"
      },
      "outputs": [],
      "source": [
        "pad_int = vocab_to_int[' ']\n",
        "\n",
        "for t in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(trainloader, model, loss_fn, optimizer)\n",
        "    with torch.no_grad():\n",
        "      print(generate(model, 'ฉันเห็น', pad_value=pad_int, predict_len=40))\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmwrYv8MImyY"
      },
      "source": [
        "# Web scraping with Beautiful soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stitl9W-IpXf"
      },
      "outputs": [],
      "source": [
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "\n",
        "def scrape_siamzone_url(d):\n",
        "    soup = BeautifulSoup(requests.get('https://www.siamzone.com/music/thailyric/%d' % d).content, 'html.parser')\n",
        "    title, artist_name = soup.find('title').text.split('|')\n",
        "    title, artist_name = title.strip(), artist_name.strip()\n",
        "    n_shares = int(soup.find('span', attrs={'class': 'sz-social-number'}).text.replace(',', ''))\n",
        "    full_lyrics = soup.find('div', attrs={'itemprop': 'articleBody'}).text.strip()\n",
        "    return {\n",
        "        'url': 'https://www.siamzone.com/music/thailyric/%d' % d,\n",
        "        'soup': soup,\n",
        "        'title': title,\n",
        "        'artist_name': artist_name,\n",
        "        'n_shares': n_shares,\n",
        "        'full_lyrics': full_lyrics\n",
        "    }\n",
        "\n",
        "def scrape_siamzone():\n",
        "    data = []\n",
        "    for i in range(14050, 16041):\n",
        "        try:\n",
        "            data.append(scrape_siamzone_url(i))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['lyrics'] = df.full_lyrics.map(clean_lyrics)\n",
        "    return df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}