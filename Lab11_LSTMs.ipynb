{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMoXdgLYHmVc",
    "outputId": "8f3aea80-2592-440c-8bdf-6afe67678ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pythainlp\n",
      "  Downloading pythainlp-3.1.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 29.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
      "Installing collected packages: pythainlp\n",
      "Successfully installed pythainlp-3.1.0\n",
      "--2022-09-27 03:17:43--  http://www.donlapark.cmustat.com/229352/thai_lyrics.csv\n",
      "Resolving www.donlapark.cmustat.com (www.donlapark.cmustat.com)... 150.107.31.67\n",
      "Connecting to www.donlapark.cmustat.com (www.donlapark.cmustat.com)|150.107.31.67|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44871532 (43M) [text/csv]\n",
      "Saving to: ‘thai_lyrics.csv’\n",
      "\n",
      "thai_lyrics.csv     100%[===================>]  42.79M  3.32MB/s    in 17s     \n",
      "\n",
      "2022-09-27 03:18:01 (2.45 MB/s) - ‘thai_lyrics.csv’ saved [44871532/44871532]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp\n",
    "!wget http://www.donlapark.cmustat.com/229352/thai_lyrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4htrTvCOhPBD"
   },
   "source": [
    "#Song lyrics generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "EQ51vFVH8uhg",
    "outputId": "0519b815-42e0-40b1-dccc-1045a827a6f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0c3ec0a6-6913-41bd-aafe-a6ba11a19e74\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>soup</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>full_lyrics</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.siamzone.com/music/thailyric/14050</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html lang=\"th\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>เนื้อเพลง แบบว่าหวั่นไหว (Ost. เด็ดปีกนางฟ้า)</td>\n",
       "      <td>กลม อรวี พินิจสารภิรมย์</td>\n",
       "      <td>ก็เธอน่ะทำให้ใจมันเต้นแรง แรง\\nแต่เขาก็ทำให้ใจ...</td>\n",
       "      <td>ก็เธอน่ะทำให้ใจมันเต้นแรง แรง\\nแต่เขาก็ทำให้ใจ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.siamzone.com/music/thailyric/14051</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html lang=\"th\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>เนื้อเพลง ที่ผ่านมา</td>\n",
       "      <td>เยิ้ม Yerm</td>\n",
       "      <td>วันแห่งความรัก ขอมอบเพลงนี้ให้ใครสักคน\\nที่ยัง...</td>\n",
       "      <td>วันแห่งความรัก ขอมอบเพลงนี้ให้ใครสักคน\\nที่ยัง...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.siamzone.com/music/thailyric/14052</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html lang=\"th\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>เนื้อเพลง ในตอนนั้น</td>\n",
       "      <td>โอม รัธพงศ์ ภูรีสิทธิ์ Youngohm</td>\n",
       "      <td>เมื่อก่อนนี้มีแค่เรา\\nในความคิดเป็นแค่เงา\\nไม่...</td>\n",
       "      <td>เมื่อก่อนนี้มีแค่เรา\\nในความคิดเป็นแค่เงา\\nไม่...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.siamzone.com/music/thailyric/14053</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html lang=\"th\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>เนื้อเพลง อยู่ในใจ</td>\n",
       "      <td>ปู พงษ์สิทธิ์ คำภีร์</td>\n",
       "      <td>ขอบคุณวันเวลา ที่ผ่านมา ขอบคุณสิ่งดีที่เธอให้\\...</td>\n",
       "      <td>ขอบคุณวันเวลา ที่ผ่านมา ขอบคุณสิ่งดีที่เธอให้\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.siamzone.com/music/thailyric/14054</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n\\n&lt;html lang=\"th\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>เนื้อเพลง ชู้กะชู้</td>\n",
       "      <td>เอ๊ะ พงศ์จักร พิษฐานพร Aeh Syndrome</td>\n",
       "      <td>เอ๊ะ ขาวใสๆ ช่างน่ามอง\\nเอ๊ะ รอยยิ้มของเธอ ทำฉ...</td>\n",
       "      <td>เอ๊ะ ขาวใสๆ ช่างน่ามอง\\nเอ๊ะ รอยยิ้มของเธอ ทำฉ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c3ec0a6-6913-41bd-aafe-a6ba11a19e74')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0c3ec0a6-6913-41bd-aafe-a6ba11a19e74 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0c3ec0a6-6913-41bd-aafe-a6ba11a19e74');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              url  \\\n",
       "0  https://www.siamzone.com/music/thailyric/14050   \n",
       "1  https://www.siamzone.com/music/thailyric/14051   \n",
       "2  https://www.siamzone.com/music/thailyric/14052   \n",
       "3  https://www.siamzone.com/music/thailyric/14053   \n",
       "4  https://www.siamzone.com/music/thailyric/14054   \n",
       "\n",
       "                                                soup  \\\n",
       "0  <!DOCTYPE HTML>\\n\\n<html lang=\"th\">\\n<head>\\n<...   \n",
       "1  <!DOCTYPE HTML>\\n\\n<html lang=\"th\">\\n<head>\\n<...   \n",
       "2  <!DOCTYPE HTML>\\n\\n<html lang=\"th\">\\n<head>\\n<...   \n",
       "3  <!DOCTYPE HTML>\\n\\n<html lang=\"th\">\\n<head>\\n<...   \n",
       "4  <!DOCTYPE HTML>\\n\\n<html lang=\"th\">\\n<head>\\n<...   \n",
       "\n",
       "                                           title  \\\n",
       "0  เนื้อเพลง แบบว่าหวั่นไหว (Ost. เด็ดปีกนางฟ้า)   \n",
       "1                            เนื้อเพลง ที่ผ่านมา   \n",
       "2                            เนื้อเพลง ในตอนนั้น   \n",
       "3                             เนื้อเพลง อยู่ในใจ   \n",
       "4                             เนื้อเพลง ชู้กะชู้   \n",
       "\n",
       "                           artist_name  \\\n",
       "0              กลม อรวี พินิจสารภิรมย์   \n",
       "1                           เยิ้ม Yerm   \n",
       "2      โอม รัธพงศ์ ภูรีสิทธิ์ Youngohm   \n",
       "3                 ปู พงษ์สิทธิ์ คำภีร์   \n",
       "4  เอ๊ะ พงศ์จักร พิษฐานพร Aeh Syndrome   \n",
       "\n",
       "                                         full_lyrics  \\\n",
       "0  ก็เธอน่ะทำให้ใจมันเต้นแรง แรง\\nแต่เขาก็ทำให้ใจ...   \n",
       "1  วันแห่งความรัก ขอมอบเพลงนี้ให้ใครสักคน\\nที่ยัง...   \n",
       "2  เมื่อก่อนนี้มีแค่เรา\\nในความคิดเป็นแค่เงา\\nไม่...   \n",
       "3  ขอบคุณวันเวลา ที่ผ่านมา ขอบคุณสิ่งดีที่เธอให้\\...   \n",
       "4  เอ๊ะ ขาวใสๆ ช่างน่ามอง\\nเอ๊ะ รอยยิ้มของเธอ ทำฉ...   \n",
       "\n",
       "                                              lyrics  \n",
       "0  ก็เธอน่ะทำให้ใจมันเต้นแรง แรง\\nแต่เขาก็ทำให้ใจ...  \n",
       "1  วันแห่งความรัก ขอมอบเพลงนี้ให้ใครสักคน\\nที่ยัง...  \n",
       "2  เมื่อก่อนนี้มีแค่เรา\\nในความคิดเป็นแค่เงา\\nไม่...  \n",
       "3  ขอบคุณวันเวลา ที่ผ่านมา ขอบคุณสิ่งดีที่เธอให้\\...  \n",
       "4  เอ๊ะ ขาวใสๆ ช่างน่ามอง\\nเอ๊ะ รอยยิ้มของเธอ ทำฉ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from pythainlp import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('thai_lyrics.csv', engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NF8se3vr9IE6",
    "outputId": "9b870ea6-4330-4200-b303-b464d035f011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ก็', 'เธอ', 'น่ะ', 'ทำให้', 'ใจ', 'มัน', 'เต้น', 'แรง', ' ', 'แรง', '\\n', 'แต่', 'เขา', 'ก็', 'ทำให้', 'ใจ', 'อยาก', 'กรี๊ด', 'รัว', ' ', 'รัว', '\\n', 'ผลัดกัน', 'มา', 'ทำคะแนน', 'จน', 'ฉัน', 'กลัว', ' ', 'กลัว', ' ', 'หัวใจ', 'วุ่นวาย', '\\n', '\\n', 'ก็', 'เธอ', 'น่ะ', 'คอย', 'เอาใจ', 'แบบ', 'โอ๊ย', 'คือ', 'ดี', '\\n', 'แต่', 'เค้า', 'ก็', 'มี', 'สไตล์', 'แบบ', 'โอ๊ย', 'คือ', 'โดน', '\\n', 'จิตใจ', 'เลย', 'มี', 'อาการ', 'แบบ', 'เริ่ม', 'ซน', ' ', 'ซน', ' ', 'นิดหนึ่ง', '\\n', '\\n', 'แบบ', 'ว่า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'วา', ' ', 'หวั่นไหว', '\\n', 'แบบ', 'ว่า', 'น่ารัก', ' ', 'น่ารัก', ' ', 'น่ารัก', ' ', 'ทั้งคู่', 'เลย', ' ', 'มัน', 'ยิ่ง', 'คิด', 'ยิ่ง', 'คิดไม่ออก', '\\n', 'กูเกิ้ล', 'ก็', 'ไม่', 'บอก', ' ', 'เธอ', 'น่า', 'เก็บ', 'ไว้', 'ทั้งสอง', 'คน', '\\n', 'แบบ', 'มัน', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นอ', 'ยด์', 'กว่า', 'ใคร', '\\n', 'จะ', 'ให้', 'เลือก', 'ก็', 'ไม่', 'ไหว', ' ', 'โจทย์', 'มัน', 'ยาก', 'เกิน', 'ทน', '\\n', 'มัน', 'เลือกไม่ได้', 'สักที', ' ', 'เลย', 'เลือกไม่ได้', 'สักที', ' ', 'ทั้งสอง', 'คน', '\\n', '\\n', 'อย่า', 'หาว่า', 'ฉัน', 'เป็น', 'คนเจ้าชู้', 'บี', 'ดู', '\\n', 'ไม่', 'ได้', 'ตั้งใจ', 'อย่า', 'เพิ่ง', 'ใส่ร้าย', 'เลย', 'ยู', '\\n', 'ไม่', 'เคย', 'จะ', 'เป็น', 'อย่างนี้', 'มา', 'มะ', 'มา', 'ดู', ' ', 'หน้า', 'คน', 'กลุ้มใจ', '\\n', '\\n', 'ก็', 'เธอ', 'น่ะ', 'คอย', 'เอาใจ', 'แบบ', 'โอ๊ย', 'คือ', 'ดี', '\\n', 'แต่', 'เค้า', 'ก็', 'มี', 'สไตล์', 'แบบ', 'โอ๊ย', 'คือ', 'โดน', '\\n', 'จิตใจ', 'เลย', 'มี', 'อาการ', 'แบบ', 'เริ่ม', 'ซน', ' ', 'ซน', ' ', 'นิดหนึ่ง', '\\n', '\\n', 'แบบ', 'ว่า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'วา', ' ', 'หวั่นไหว', '\\n', 'แบบ', 'ว่า', 'น่ารัก', ' ', 'น่ารัก', ' ', 'น่ารัก', ' ', 'ทั้งคู่', 'เลย', ' ', 'มัน', 'ยิ่ง', 'คิด', 'ยิ่ง', 'คิดไม่ออก', '\\n', 'กูเกิ้ล', 'ก็', 'ไม่', 'บอก', ' ', 'เธอ', 'น่า', 'เก็บ', 'ไว้', 'ทั้งสอง', 'คน', '\\n', 'แบบ', 'มัน', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นอ', 'ยด์', 'กว่า', 'ใคร', '\\n', 'จะ', 'ให้', 'เลือก', 'ก็', 'ไม่', 'ไหว', ' ', 'โจทย์', 'มัน', 'ยาก', 'เกิน', 'ทน', '\\n', 'มัน', 'เลือกไม่ได้', 'สักที', ' ', 'เลย', 'เลือกไม่ได้', 'สักที', ' ', 'ทั้งสอง', 'คน', '\\n', '\\n', 'แบบ', 'ว่า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'ว้า', ' ', 'วา', ' ', 'หวั่นไหว', '\\n', 'แบบ', 'ว่า', 'น่ารัก', ' ', 'น่ารัก', ' ', 'น่ารัก', ' ', 'ทั้งคู่', 'เลย', ' ', 'มัน', 'ยิ่ง', 'คิด', 'ยิ่ง', 'คิดไม่ออก', '\\n', 'กูเกิ้ล', 'ก็', 'ไม่', 'บอก', ' ', 'เธอ', 'น่า', 'เก็บ', 'ไว้', 'ทั้งสอง', 'คน', '\\n', 'แบบ', 'มัน', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นะ', ' ', 'นอ', 'ยด์', 'กว่า', 'ใคร', '\\n', 'จะ', 'ให้', 'เลือก', 'ก็', 'ไม่', 'ไหว', ' ', 'โจทย์', 'มัน', 'ยาก', 'เกิน', 'ทน', '\\n', 'อย่า', 'เพิ่ง', 'หนี', 'และ', 'อย่า', 'เพิ่ง', 'บ่น', ' ', 'ถ้า', 'รัก', 'ฉัน', 'แล้ว', 'ต้อง', 'ทน', ' ', 'นะ', 'ทั้งสอง', 'คน']\n"
     ]
    }
   ],
   "source": [
    "tokenized_lyrics = df['lyrics'].map(word_tokenize)\n",
    "print(tokenized_lyrics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEg_FFZcg2hn"
   },
   "source": [
    "### Convert from words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laZhsugj40XF"
   },
   "outputs": [],
   "source": [
    "\n",
    "#[[song , number , one],[song , number , two]] -> [song , number , one , song , number , two]\n",
    "def flatten(ls):\n",
    "    \"\"\"\n",
    "    Flatten list of list\n",
    "    \"\"\"\n",
    "    return list(chain.from_iterable(ls))\n",
    "\n",
    "#[song , number ,one, number, two] -> [1,2,3,2,4] and [1,2,3] -> [song , number , one]\n",
    "def create_lookup_dict(tokenized_lyrics, n_min=None):\n",
    "    \"\"\"\n",
    "    Create lookup dictionary from list of words (lyrics)\n",
    "    \"\"\"\n",
    "    word_counts = Counter(tokenized_lyrics)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    if n_min is not None:\n",
    "        sorted_vocab = {k: v for k, v in word_counts.items() if v >= n_min}\n",
    "    vocab_to_int = {word: i for i, word in enumerate(sorted_vocab, 0)}\n",
    "    int_to_vocab = {i: word for word, i in vocab_to_int.items()}\n",
    "    return (vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7h76Ddh5pxy"
   },
   "outputs": [],
   "source": [
    "tokenized_lyrics = flatten(tokenized_lyrics)\n",
    "tokenized_lyrics = [token if token is not '\\n' else ' ' for token in tokenized_lyrics]\n",
    "word_counts = Counter(tokenized_lyrics)\n",
    "vocab_to_int, int_to_vocab = create_lookup_dict(tokenized_lyrics, n_min=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i49_sKArgkeQ",
    "outputId": "7d75ed40-2819-4d19-d12a-0b110173d677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int[\"ใคร\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ji5YtYv2vqq4",
    "outputId": "037ec1bc-a5e9-4f44-c2f6-32d7d24d358d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10035"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ZDeFF62ngkmN",
    "outputId": "79a854c0-4706-417c-f7b1-5e82b5780e24"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ว่า'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgUDR6WZgqCi"
   },
   "source": [
    "### Create Features (20 words in a song) and Target (the next word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TaH7s1JS6rXB"
   },
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "\n",
    "tokenized_indices = [vocab_to_int.get(token, 0) for token in tokenized_lyrics]\n",
    "\n",
    "X, target = [], []\n",
    "for n in range(0, len(tokenized_indices) - sequence_length, 1):\n",
    "  x = tokenized_indices[n: n + sequence_length]\n",
    "  y = tokenized_indices[n + sequence_length]\n",
    "  X.append(np.array(x))\n",
    "  target.append(y)\n",
    "X = np.array(X)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UP_j2yBfgjEP",
    "outputId": "28a75019-4470-47a0-93a0-1e07b14a2906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7,    1,  292,   65,   22,   10,  501,  361,    0,  361,    0,\n",
       "         17,   32,    7,   65,   22,   25, 4481, 1487,    0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Re-6oe-gjdB",
    "outputId": "791e3d12-cfe9-46f7-9c35-6b881dddacb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M42FcfW2LgiH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super(MyDataSet, self).__init__()\n",
    "    self._X = X\n",
    "    self._y = y\n",
    "\n",
    "  def __len__(self):\n",
    "    return self._X.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    X = self._X[index]\n",
    "    y = self._y[index]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9FTHz2eLqpW"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# Classification\n",
    "NUM_CLASSES = 10035\n",
    "\n",
    "dataset = MyDataSet(X, target)\n",
    "\n",
    "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxaVQAwqUTwl"
   },
   "source": [
    "## New layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4L6bwtBUZnw"
   },
   "source": [
    "1. `nn.Embedding(num_vocabs, hidden_dim)`\n",
    "\n",
    "![emb](https://miro.medium.com/max/720/1*NuWIU2Iew3Bm8NR78tRj8A.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IxIMSJtUs3Y",
    "outputId": "45bb7434-dff6-4b22-e21f-c4fb4e695a25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "output = embedding(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPuELnL_UnsX"
   },
   "source": [
    "2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMDmCYN6Svkb"
   },
   "source": [
    "![lstm](https://i.stack.imgur.com/sBEBp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZivdouMU0F2",
    "outputId": "18e3d0e3-eb19-4ec5-8685-30b321ed64be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (h1, c1) = lstm(input, (h0, c0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwDMjEUPdn6Z"
   },
   "source": [
    "### Exercise 1: fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOXkBy9ENokC"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "\n",
    "        # TODO 1: Fill in the layers' parameters, with all hidden dimensions = 128\n",
    "        self.embeddings = nn.Embedding(, )\n",
    "        self.lstm = nn.LSTM(, , dropout = 0.2, num_layers = 2)\n",
    "        self.fc = nn.Linear(, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), \n",
    "        # so we need to transpose the input\n",
    "        x = x.t()\n",
    "        # TODO 2: Apply the Embedding layer\n",
    "        x = self.embeddings(x)\n",
    "        # TODO 3: Apply the LSTM layer (note: LSTM's output is a tuple!)\n",
    "        h, _ = self.lstm(x)\n",
    "        # Only need to keep the last element of the sequence\n",
    "        ht=h[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpZ_4U85IqcB"
   },
   "outputs": [],
   "source": [
    "model = Simple_LSTM().to('cuda')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPALHPWyeH_V"
   },
   "source": [
    "### Exercise 2: fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLRparXRIrZ9"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def generate(model, start_word, int_to_vocab, pad_value=0, predict_len=100):\n",
    "    \n",
    "    words = word_tokenize(start_word)\n",
    "    start_word_ids = []\n",
    "    predicted = words\n",
    "    \n",
    "    word_ids = [vocab_to_int.get(word, pad_value) for word in words]\n",
    "    #[28,15,16] -> [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,15,16]\n",
    "\n",
    "    current_seq = [np.pad(word_ids, (20 - len(word_ids), pad_value), 'constant')]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "        current_seq = torch.LongTensor(current_seq).to('cuda')\n",
    "        # get the next word probabilities\n",
    "        p = model(current_seq)\n",
    "        p = nn.Softmax(dim=1)(p).cpu().detach().numpy()\n",
    "        # p = [[0.1,0.2,0.05,0.03,0.02,0.3,0.2,0.1]]\n",
    "        p = p[0]\n",
    "        # p = [0.1,0.2,0.05,0.03,0.02,0.3,0.2,0.1]\n",
    "\n",
    "\n",
    "        # Sample from probability distribution p\n",
    "        word_i = np.random.choice(np.arange(0,p.shape[0]),p=p)\n",
    "        #word_i is an integer representing a word.\n",
    "        \n",
    "        #### TODO: Fill in the following two lines of code#########\n",
    "        # Convert from word_i (int)--> word (str)\n",
    "        # and append the word from 1. into `predicted` list.\n",
    "\n",
    "        ##################end#####################################\n",
    "        \n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        current_seq = current_seq.cpu().detach().numpy()\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    gen_sentences = ''.join(predicted)    \n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-9hflaPec0j"
   },
   "source": [
    "### Exercise 3: use `generate` function to generate three more songs. You may try using different starting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "GInZpHdqI8p2",
    "outputId": "66af82b9-1ec1-4790-b326-4e16828051d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 9.203841  [    0/370475]\n",
      "loss: 5.516397  [128000/370475]\n",
      "loss: 5.002436  [256000/370475]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d3717313b1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ใคร'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-5a29d62dc645>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, loss_fn, optimizer)\n",
    "    print(generate(model, 'ใคร', int_to_vocab, predict_len=100))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmwrYv8MImyY"
   },
   "source": [
    "# Web scraping with Beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Stitl9W-IpXf"
   },
   "outputs": [],
   "source": [
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def scrape_siamzone_url(d):\n",
    "    soup = BeautifulSoup(requests.get('https://www.siamzone.com/music/thailyric/%d' % d).content, 'html.parser')\n",
    "    title, artist_name = soup.find('title').text.split('|')\n",
    "    title, artist_name = title.strip(), artist_name.strip()\n",
    "    n_shares = int(soup.find('span', attrs={'class': 'sz-social-number'}).text.replace(',', ''))\n",
    "    full_lyrics = soup.find('div', attrs={'itemprop': 'articleBody'}).text.strip()\n",
    "    return {\n",
    "        'url': 'https://www.siamzone.com/music/thailyric/%d' % d,\n",
    "        'soup': soup, \n",
    "        'title': title,\n",
    "        'artist_name': artist_name,\n",
    "        'n_shares': n_shares,\n",
    "        'full_lyrics': full_lyrics\n",
    "    }\n",
    "\n",
    "def scrape_siamzone():\n",
    "    data = []\n",
    "    for i in range(14050, 16041):\n",
    "        try:\n",
    "            data.append(scrape_siamzone_url(i))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df['lyrics'] = df.full_lyrics.map(clean_lyrics)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
