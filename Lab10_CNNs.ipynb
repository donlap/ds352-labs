{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donlap/ds352-labs/blob/main/Lab10_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #10"
      ],
      "metadata": {
        "id": "R3EHk_vLhxDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision # For utils.make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm # For nice progress bars\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "t-jV4RoaQjuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a dataset of pizza, stead and sushi images ([source](https://www.learnpytorch.io/04_pytorch_custom_datasets/))"
      ],
      "metadata": {
        "id": "65iWpYjuo1b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q pizza_steak_sushi.zip"
      ],
      "metadata": {
        "id": "pkoZPKjOcixg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"train\"\n",
        "test_dir = \"test\""
      ],
      "metadata": {
        "id": "w2yv5OBCdsNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "\n",
        "![augmentation](https://miro.medium.com/max/700/0*LR1ZQucYW96prDte)\n",
        "\n",
        "See more transformations in [Pytorch documentation](https://docs.pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended)"
      ],
      "metadata": {
        "id": "lGMVh81YgMTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define data transformations\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize all images to 224x224\n",
        "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # Normalize pixel values (ImageNet statistics)\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 2. Create datasets using ImageFolder\n",
        "train_data = # Write your code here\n",
        "test_data = # Write your code here\n",
        "\n",
        "# Get class names and their mapping\n",
        "class_names = train_data.classes\n",
        "class_to_idx = train_data.class_to_idx\n",
        "\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Class to index mapping: {class_to_idx}\")\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of testing samples: {len(test_data)}\")\n",
        "\n",
        "# 3. Create DataLoaders\n",
        "BATCH_SIZE = 32 # You can experiment with different batch sizes\n",
        "\n",
        "train_dataloader = # Write your code here\n",
        "\n",
        "test_dataloader = # Write your code here\n",
        "\n",
        "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
        "print(f\"Number of batches in testing DataLoader: {len(test_dataloader)}\")\n",
        "\n",
        "# Let's visualize a sample image and its label\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0)) # Convert from (C, H, W) to (H, W, C)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean # Undo normalization\n",
        "    inp = np.clip(inp, 0, 1) # Clip pixel values to [0, 1]\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[:4]) # Show first 4 images\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "imshow(out, title=[class_names[x] for x in classes[:4]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CXgPlr4Vt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Implement and Train LeNet\n",
        "\n",
        "LeNet-5 is one of the earliest convolutional neural networks, developed by Yann LeCun et al. in the 1990s. While originally designed for smaller images (like MNIST digits), we will adapt its architecture for our 224x224 pixel images.\n",
        "\n",
        "![lenet5](http://d2l.ai/_images/lenet.svg)\n",
        "\n",
        "### LeNet Architecture (Adapted for 224x224 input, 3 output classes):\n",
        "\n",
        "1.  **Input Layer**: 3x224x224 image (RGB channels).\n",
        "2.  **Conv1**:\n",
        "    *   Input Channels: 3\n",
        "    *   Output Channels: 6\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "3.  **Pool1**:\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "4.  **Conv2**:\n",
        "    *   Input Channels: 6\n",
        "    *   Output Channels: 16\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "5.  **Pool2**:\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "6.  **Flatten**: Flatten the 3D feature maps into a 1D vector.\n",
        "    *   *Hint*: After Pool2, the feature map size will be `16 * (something) * (something)`. You'll need to calculate this dimension based on the input size and the conv/pool operations.\n",
        "        *   Input (224x224) -> Conv1 (224-5+1 = 220x220)\n",
        "        *   Pool1 (220/2 = 110x110)\n",
        "        *   Conv2 (110-5+1 = 106x106)\n",
        "        *   Pool2 (106/2 = 53x53)\n",
        "        *   So, the output of Pool2 will be `16 * 53 * 53`.\n",
        "7.  **FC1 (Fully Connected 1)**:\n",
        "    *   Input Features: `16 * 53 * 53`\n",
        "    *   Output Features: 120\n",
        "    *   Activation: ReLU\n",
        "8.  **FC2 (Fully Connected 2)**:\n",
        "    *   Input Features: 120\n",
        "    *   Output Features: 84\n",
        "    *   Activation: ReLU\n",
        "9.  **Output Layer (FC3)**:\n",
        "    *   Input Features: 84\n",
        "    *   Output Features: 3 (for pizza, steak, sushi)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Implement the `LeNet` class following the architecture above.\n",
        "2.  Instantiate the model and move it to the `device` (GPU/CPU).\n",
        "3.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer (`optim.Adam`).\n",
        "4.  Train the LeNet model for a few epochs (e.g., 5-10).\n",
        "5.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "mz24H8yLd7Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3T3jd1kylKlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(LeNet, self).__init__()\n",
        "        # Write your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Write your code here\n",
        "\n",
        "        return x\n",
        "\n",
        "# --- Your Code Below ---\n",
        "\n",
        "# Training loop function (to be reused)\n",
        "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs):\n",
        "    print(f\"\\n--- Training {model.__class__.__name__} for {num_epochs} epochs ---\")\n",
        "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
        "        # Training phase\n",
        "        model.train() # Set model to training mode\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_dataloader:\n",
        "            # Write your code here\n",
        "            # 1. Move inputs and labels to device\n",
        "\n",
        "            # 2. Zero the gradient\n",
        "\n",
        "            # 3. Make predictions\n",
        "\n",
        "            # 4. Calculate the loss\n",
        "\n",
        "            # 5. Calculate the gradients\n",
        "\n",
        "            # 6. Update model's parameters\n",
        "\n",
        "            # Calculate total loss and accuracy\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_train_loss = train_loss / len(train_dataloader.dataset)\n",
        "        epoch_train_acc = train_correct / train_total\n",
        "        results[\"train_loss\"].append(epoch_train_loss)\n",
        "        results[\"train_acc\"].append(epoch_train_acc)\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        test_loss = 0.0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "            for inputs, labels in test_dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_test_loss = test_loss / len(test_dataloader.dataset)\n",
        "        epoch_test_acc = test_correct / test_total\n",
        "        results[\"test_loss\"].append(epoch_test_loss)\n",
        "        results[\"test_acc\"].append(epoch_test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} | \"\n",
        "              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.4f}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "ok-F447nVwL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate LeNet model\n",
        "lenet_model = LeNet(num_classes=len(class_names)).to(device)\n",
        "print(lenet_model)"
      ],
      "metadata": {
        "id": "3lgFw1MDlPHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LeNet model\n",
        "lenet_results = train_model(lenet_model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "id": "q_li-wN3lTB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(lenet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(lenet_results['test_loss'], label='Test Loss')\n",
        "plt.title('LeNet Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(lenet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(lenet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('LeNet Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSQQpyB_lU-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 1:\n",
        "1.  How did the LeNet model perform on the test set? What was its final test accuracy?\n",
        "    *   **Your Answer:**"
      ],
      "metadata": {
        "id": "o6CXS-w7ed8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Transfer Learning\n",
        "\n",
        "Training a deep CNN from scratch can be computationally expensive and requires a large amount of data. Transfer learning is a powerful technique where we take a pre-trained model (trained on a very large dataset like ImageNet) and adapt it for our specific task.\n",
        "\n",
        "Here, we will use `EfficientNet_B0` from `torchvision.models`, which is a powerful and efficient model.\n",
        "\n",
        "[List of pretrained models in Pytorch](https://docs.pytorch.org/vision/main/models.html#classification)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Load a pre-trained `EfficientNet_B0` model.\n",
        "2.  \"Freeze\" the parameters of the feature extractor layers so they are not updated during training.\n",
        "3.  Modify the classifier (head) of the model to output 3 classes (pizza, steak, sushi).\n",
        "    *   *Hint*: For `EfficientNet_B0`, the classifier is typically accessed via `model.classifier`. You'll need to replace its last layer.\n",
        "4.  Instantiate the modified model and move it to the `device`.\n",
        "5.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer.\n",
        "    *   *Important*: Ensure the optimizer *only* updates the parameters of the new, unfrozen layers.\n",
        "6.  Train the transfer learning model for a few epochs (e.g., 5-10).\n",
        "7.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "JpAwzQUBe6Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load a pre-trained EfficientNet_B0 model\n",
        "efficientnet_model = models.efficientnet_b0(pretrained=True)\n",
        "print(\"Original EfficientNet_B0 classifier head:\")\n",
        "print(efficientnet_model.classifier)"
      ],
      "metadata": {
        "id": "XWeUVDVFmgoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Freeze all parameters in the feature extractor part\n",
        "#### Write your code here\n",
        "\n",
        "# 3. Modify the classifier head for 3 classes\n",
        "# EfficientNet's classifier is a sequential block, typically with a dropout and a linear layer.\n",
        "# We need to replace the last linear layer.\n",
        "# 3.1 Get input features to the last linear layer\n",
        "\n",
        "\n",
        "# 3.2 Change the head (the classifier) of the model\n",
        "#     Use nn.Sequential() to create a small model with a sequence of layers\n",
        "\n",
        "\n",
        "efficientnet_model = efficientnet_model.to(device)\n",
        "print(\"\\nModified EfficientNet_B0 classifier head:\")\n",
        "print(efficientnet_model.classifier)"
      ],
      "metadata": {
        "id": "Mpycmt3NVy5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which parameters are being trained\n",
        "print(\"\\nParameters to be trained:\")\n",
        "params_to_update = []\n",
        "for name, param in efficientnet_model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(name)"
      ],
      "metadata": {
        "id": "-J2h_y-cm8Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define loss function and optimizer (only for the new parameters)\n",
        "criterion_tl = # Write your code here\n",
        "optimizer_tl = # Write your code here"
      ],
      "metadata": {
        "id": "nANDOtVMm8hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train the transfer learning model\n",
        "efficientnet_results = train_model(efficientnet_model, train_dataloader, test_dataloader, criterion_tl, optimizer_tl, num_epochs=10)"
      ],
      "metadata": {
        "id": "LON7Fm9km8nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(efficientnet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(efficientnet_results['test_loss'], label='Test Loss')\n",
        "plt.title('EfficientNet Loss (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(efficientnet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(efficientnet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('EfficientNet Accuracy (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1FfE526nNl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 2:\n",
        "1.  Compare the performance of the LeNet model (from Part 1) with the transfer learning model (EfficientNet_B0). Which one performed better and why do you think that is?\n",
        "    *   **Your Answer:**\n",
        "2.  Explain the concept of \"freezing\" layers in transfer learning. Why is it done, and what are its benefits?\n",
        "    *   **Your Answer:**\n",
        "3.  What challenges might arise when using transfer learning on a dataset that is significantly different from the dataset the pre-trained model was originally trained on (e.g., medical images vs. ImageNet)?\n",
        "    *   **Your Answer:**\n",
        "4.  Choose 3 images from the test set. Display the images and show their predicted classes."
      ],
      "metadata": {
        "id": "8gyxRyRHfcOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of making prediction on an image\n",
        "\n",
        "x = torch.rand(28, 28, 1)  # an image"
      ],
      "metadata": {
        "id": "No6lZcHCg_Ny"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFDj0DvKLSYcDBAWSQri8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}