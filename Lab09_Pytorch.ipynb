{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE5JHoY48UdL"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-nQb7jGS3PJ"
      },
      "source": [
        "There are several deep learning frameworks in Python.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/2560px-PyTorch_logo_black.svg.png\" width=\"100\"/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg\" width=\"40\"/><img src=\"https://assets-global.website-files.com/621e749a546b7592125f38ed/62277da165ed192adba475fc_JAX.jpg\" width=\"100\"/>\n",
        "\n",
        "In this Lab, we will use PyTorch [PyTorch documentation](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/donlapark/ds352-labs.git"
      ],
      "metadata": {
        "id": "xgWqscGrMKlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzJSrt8CSv4p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEsXce8XuwIW"
      },
      "source": [
        "# Tensor basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr1d7mpfrQ-W"
      },
      "source": [
        "## Basic tensor creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoo78UqZZBmo"
      },
      "source": [
        "### Creating a scalar (1D) tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QkirMVZUpfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2D_T5PPZI4L"
      },
      "source": [
        "### Convert a tensor to scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSkS98iYXVZI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLUTVuu8ZPCV"
      },
      "source": [
        "### Creating 2D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST-ZldGXX9SY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL1rmhg8rVgY"
      },
      "source": [
        "## Tensor and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LSTMBVNZjAu"
      },
      "source": [
        "### Convert from tensor to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4LkkrQdYbLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcFexnBYZn73"
      },
      "source": [
        "### Convert from numpy array to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDRLWyGkZmjM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bLYQUdDb47c"
      },
      "source": [
        "## Basic operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ZL-UgraQZG"
      },
      "outputs": [],
      "source": [
        "D =\n",
        "\n",
        "E =\n",
        "\n",
        "print(D)\n",
        "print(E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_k3thRzrdpd"
      },
      "source": [
        "### Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1XwpoNaakY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJki4afrf0m"
      },
      "source": [
        "### Matrix transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IumkARr4g3Nv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuwWEOBYcbiL"
      },
      "source": [
        "## Creating a specific type of tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg757DJLaoqh"
      },
      "outputs": [],
      "source": [
        "print(torch.zeros(2,3))\n",
        "# print(torch.ones(2,3))\n",
        "# print(torch.rand(2,3))\n",
        "# print(torch.randn(2,3))  # sample each number from N(0, 1)\n",
        "# print(torch.arange(9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUeodCiLrofw"
      },
      "source": [
        "## Tensor's shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTX5WOHhVsB"
      },
      "source": [
        "### Checking the shape of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzn5Lyqfhcmf"
      },
      "outputs": [],
      "source": [
        "F = torch.zeros((4, 5))\n",
        "print(F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf21H-EvgE87"
      },
      "source": [
        "### Changing the shape of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o71IJ7_ic1U8"
      },
      "outputs": [],
      "source": [
        "G = torch.arange(6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view and reshape\n"
      ],
      "metadata": {
        "id": "Gha5achmPymE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZgFYT5gd2_"
      },
      "source": [
        "In general, use `reshape`, but if you are worried about the memory usage, use `view`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftVXJ-3ur9yk"
      },
      "source": [
        "## PyTorch and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TmzZR23sKOW"
      },
      "source": [
        "check if GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSiXGmqrqyzw"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjDt08_7sMxz"
      },
      "outputs": [],
      "source": [
        "Q = torch.tensor([1, 2, 3])\n",
        "print(Q.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BitUf-RtdG3"
      },
      "outputs": [],
      "source": [
        "R = Q.cuda()\n",
        "print(Q.device)\n",
        "print(R.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbsTOQ-Itiax"
      },
      "outputs": [],
      "source": [
        "R.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a neural network in PyTorch"
      ],
      "metadata": {
        "id": "BcbkxmWA74vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chihuahua or Muffin?\n",
        "\n",
        "<center><img src=\"https://donlapark.pages.dev/229352/lab09-preview.jpg\" width=\"500\"/></center>"
      ],
      "metadata": {
        "id": "nGIdhbtd8T2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data preparation"
      ],
      "metadata": {
        "id": "327TUVAY-GWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load images, resize them to 128x128, and normalize the pixels to be in 0 - 1 range"
      ],
      "metadata": {
        "id": "zOBcEplu9fen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkI3ITOLt2S6"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                transforms.ToTensor()])  # transform pixels to be in 0 - 1 range\n",
        "\n",
        "dataset = dataset = datasets.ImageFolder(root=\"ds352-labs/lab09-data/train\",\n",
        "                                         transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the dataset into training (80%), validation (20%)"
      ],
      "metadata": {
        "id": "y_NMJJiW9w7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "oPI8NPnp9ctV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the datasets into DataLoader"
      ],
      "metadata": {
        "id": "ToRdaB3M90qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=10,\n",
        "                          shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset,\n",
        "                        batch_size=len(val_dataset),\n",
        "                        shuffle=False)"
      ],
      "metadata": {
        "id": "kVPWfJt_900l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do the same for the test images"
      ],
      "metadata": {
        "id": "DXWUYAe398Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.ImageFolder(root=\"ds352-labs/lab09-data/test\",\n",
        "                                    transform=transform)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=len(test_dataset),\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "0DE9UZxZ-B9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Looking at the first minibatch"
      ],
      "metadata": {
        "id": "bAr3zICjAQ7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = iter(train_loader)\n",
        "X, y = next(train_batches)\n",
        "\n",
        "print(X.shape)  # (batch_size, channel, height, weight)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "DsbiahaH_ynd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize the first four images in the batch"
      ],
      "metadata": {
        "id": "4pKwuqvIA7Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:4]  # Select the first 4 images\n",
        "X = X.numpy().transpose(0, 2, 3, 1)  # Convert from (B, C, H, W) to (B, H, W, C)\n",
        "\n",
        "# Plot images\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
        "for i in range(4):\n",
        "    axes[i].imshow(X[i])\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(y[:4])"
      ],
      "metadata": {
        "id": "zQDD_t91AZ_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Build a simple logistic regression\n",
        "\n",
        "<center><img src=\"https://donlapark.pages.dev/229352/logistic.png\" width=\"300\"/></center>"
      ],
      "metadata": {
        "id": "hr4ZT0OFA_uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important component of the model class is the `__init__` method and the `forward` method.  \n",
        "  \n",
        "[Activation functions in PyTorch](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity). The most important ones are [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), [Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html), [Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html)."
      ],
      "metadata": {
        "id": "k_ZfXfKCDFkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLogisticRegression(nn.Module):\n"
      ],
      "metadata": {
        "id": "_FPkDKi9CnyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Initialize training components"
      ],
      "metadata": {
        "id": "W-CprLjPBYl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize the model and loss function"
      ],
      "metadata": {
        "id": "tkEoVjYjCdfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Loss functions in PyTorch](https://pytorch.org/docs/stable/nn.html#loss-functions). Most important ones are [MSE](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html), [Binary cross, entropy](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html), [Categorical cross entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)."
      ],
      "metadata": {
        "id": "r9sIWVitYoK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLogisticRegression()\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "GnUa4i_fBXcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manually setting initial weights to zero for demonstration"
      ],
      "metadata": {
        "id": "jLa6AhMZBcZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for layer in model.modules():\n",
        "      if isinstance(layer, nn.Linear):\n",
        "          layer.weight.zero_()\n",
        "          layer.bias.zero_()"
      ],
      "metadata": {
        "id": "x9v3LrAfBci2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create two lists to collect training and validation losses"
      ],
      "metadata": {
        "id": "pwf_EFyvBrWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store the loss values for plotting\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "metadata": {
        "id": "WH7y788rBrhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Specify the learning rate"
      ],
      "metadata": {
        "id": "DrYHJN5tFjCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "4hvUj4ZcFjKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Training the model with gradient descent"
      ],
      "metadata": {
        "id": "KB0gOHHrFsLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert the dataloader into minibatches"
      ],
      "metadata": {
        "id": "YSA2AqK7F2E-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Slbap3CpFsfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make a prediction on the minibatch (Forward pass)"
      ],
      "metadata": {
        "id": "ZPSgs0ZDF9bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#y_hat = y_hat[:, 0]\n",
        "#y = y.to(torch.float32)"
      ],
      "metadata": {
        "id": "V-Kgb2zhGteA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate the loss function"
      ],
      "metadata": {
        "id": "vzyJ9MyQGto1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that `criterion()` is our binary cross-entropy loss (`BCELoss`)."
      ],
      "metadata": {
        "id": "iIvXv7a5H0tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the loss\n"
      ],
      "metadata": {
        "id": "RclJ1jKiGtyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate the gradient (Backward pass)"
      ],
      "metadata": {
        "id": "H3k4jXI4Gt6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward pass: compute the gradient of the loss w.r.t. model parameters\n"
      ],
      "metadata": {
        "id": "h39QSy3EGuCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "id": "7weYyh6UWDFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perform a gradient descent step"
      ],
      "metadata": {
        "id": "hUNXcIxMG5Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Careful! We must not include this step in the gradient calculation, hence the use of `with torch.no_grad()`."
      ],
      "metadata": {
        "id": "9pG-9dE8IVIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually update the weights using the gradient descent rule\n",
        "\n",
        "\n",
        "# Zero the gradients after updating\n",
        "model.zero_grad()"
      ],
      "metadata": {
        "id": "INEXFZDNG5bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do the same for the validation set"
      ],
      "metadata": {
        "id": "TFWFz6qkITT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Careful! Anything in the validation step must not be included in the gradient calculation, hence the use of `with torch.no_grad()`."
      ],
      "metadata": {
        "id": "HoYwFcRxIghc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for X, y in val_loader:\n",
        "    y_hat = model(X)\n",
        "    y_hat = y_hat[:, 0]\n",
        "    y = y.to(torch.float32)\n",
        "    val_loss = criterion(y_hat, y)\n",
        "    val_losses.append(val_loss.item())"
      ],
      "metadata": {
        "id": "HxbEw91dCuCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_losses)\n",
        "print(val_losses)"
      ],
      "metadata": {
        "id": "ue8xC7LMV2m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine everything together."
      ],
      "metadata": {
        "id": "XEGS9Gi5JB5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the previous steps for 20 **epochs** and plot the training and validation losses."
      ],
      "metadata": {
        "id": "2wxuMkbbJVmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleLogisticRegression()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for layer in model.modules():\n",
        "      if isinstance(layer, nn.Linear):\n",
        "          layer.weight.zero_()\n",
        "          layer.bias.zero_()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "for epoch in range(10):\n",
        "  for X, y in train_loader:\n",
        "    y_hat = model(X)\n",
        "    y_hat = y_hat[:, 0]\n",
        "    y = y.to(torch.float32)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "    # Zero the gradients after updating\n",
        "    model.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for X, y in val_loader:\n",
        "        y_hat = model(X)\n",
        "        y_hat = y_hat[:, 0]\n",
        "        y = y.to(torch.float32)\n",
        "        val_loss = criterion(y_hat, y)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(range(1, len(train_losses)+1), train_losses, marker='o', label='Training Loss')\n",
        "plt.plot(range(1, len(val_losses)+1), val_losses, marker='x', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss per Batch')\n",
        "plt.xlabel('Batch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vmOxV1m5JCNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBZ3f66AFye"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "In this exercise, we will add more layers to our classification model.\n",
        "\n",
        "<img src=\"https://donlapark.pages.dev/229352/lab09-architecture.png\" width=\"450\"/>\n",
        "\n",
        "1. Create a neural network with 3 hidden layers as shown in the picture.\n",
        "\n",
        "2. Train the model with learning rate = 1e-2, 1e-3, 1e-4, 1e-5, and answer the following questions.\n",
        "    2.1 What value of learning rate do you **think** is the best? Please explain your reason.\n",
        "    2.2 What happens to the training losses if your learning rate is too large?\n",
        "    2.3 What happens to the training losses if your learning rate is too small?\n",
        "\n",
        "3. After finish training your model. Make the predictions on the test set and compute the accuracy. You may use the provided code below.\n",
        "\n",
        "4. Use `plt.imshow()` to display at least four images that are incorrectly classified by this model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this code to calculate test accuracy\n",
        "with torch.no_grad():\n",
        "  test_batches = iter(test_loader)\n",
        "  X, y = next(test_batches)\n",
        "  y_hat = model(X)\n",
        "  y_hat = y_hat[:, 0]\n",
        "  y_hat = (y_hat > 0.5).float()  # the predictions\n",
        "  ##TODO: compute accuracy\n"
      ],
      "metadata": {
        "id": "3uTeAOXwShVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WJf7w8xStzT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}